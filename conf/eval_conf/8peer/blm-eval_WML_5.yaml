MRL_dim_idx: 0
MRL_enabled: true
batch_size: 128
device: cuda:0
evaluate_ensemble: false
max_length: 256
model_args_path: /home/coder/generative-ai-research-babylm/conf/blm-main.yaml
model_path: /home/coder/generative-ai-research-babylm/models/WML/n_peer_8/GPT2_WML_n_peer_8peer_5_ckpt.pt
temperature: 0.1
tokenizer_model_path: /home/coder/generative-ai-research-babylm/models/tokenizer/train_10M/GPT2_WML
top_k: 20
